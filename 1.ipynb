{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ansl6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "c:\\Users\\ansl6\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_12476\\958172938.py\", line 89, in upload_image\n",
      "    caption, story, kannada_story, time_taken, efficiency, bleu, meteor = image_to_story(file_path)\n",
      "                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_12476\\958172938.py\", line 78, in image_to_story\n",
      "    speak_kannada(kannada_story, \"audio_stories/kannada_story.mp3\")\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_12476\\958172938.py\", line 35, in speak_kannada\n",
      "    tts.save(filepath)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\Lib\\site-packages\\gtts\\tts.py\", line 334, in save\n",
      "    with open(str(savefile), \"wb\") as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'audio_stories\\\\audio_stories/kannada_story.mp3'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Text, Scrollbar\n",
    "import time\n",
    "import pyttsx3\n",
    "import os\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "translator = GoogleTranslator(source=\"en\", target=\"kn\")\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "def speak_kannada(text, filename):\n",
    "    os.makedirs(\"audio_stories\", exist_ok=True)\n",
    "    filepath = os.path.join(\"audio_stories\", filename)\n",
    "    tts = gTTS(text=text, lang=\"kn\")\n",
    "    tts.save(filepath)\n",
    "    audio = AudioSegment.from_file(filepath, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def generate_caption(image):\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    return blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "\n",
    "def generate_story(caption, max_length=150):\n",
    "    enriched_prompt = f\"{caption}. Once upon a time, \"\n",
    "    inputs = gpt_tokenizer.encode(enriched_prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = gpt_model.generate(inputs, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.8)\n",
    "    return gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def translate_to_kannada(text):\n",
    "    return translator.translate(text)\n",
    "\n",
    "def calculate_metrics(story, caption):\n",
    "    reference = caption.split()\n",
    "    hypothesis = story.split()\n",
    "    bleu = sentence_bleu([reference], hypothesis)\n",
    "    meteor = meteor_score([reference], hypothesis)\n",
    "    return bleu, meteor\n",
    "\n",
    "def image_to_story(path):\n",
    "    start_time = time.time()\n",
    "    image = load_image(path)\n",
    "    caption = generate_caption(image)\n",
    "    story = generate_story(caption)\n",
    "    kannada_story = translate_to_kannada(story)\n",
    "    time_taken = time.time() - start_time\n",
    "    efficiency = len(story.split()) / time_taken if time_taken > 0 else 0\n",
    "    bleu, meteor = calculate_metrics(story, caption)\n",
    "    \n",
    "    os.makedirs(\"generated_stories\", exist_ok=True)\n",
    "    story_filename = os.path.join(\"generated_stories\", \"story.txt\")\n",
    "    with open(story_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Caption: {caption}\\n\\n{story}\\n\\nKannada Story:\\n{kannada_story}\")\n",
    "    \n",
    "    speak_kannada(kannada_story, \"audio_stories/kannada_story.mp3\")\n",
    "    return caption, story, kannada_story, time_taken, efficiency, bleu, meteor\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = Image.open(file_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "        \n",
    "        caption, story, kannada_story, time_taken, efficiency, bleu, meteor = image_to_story(file_path)\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        \n",
    "        story_text.delete(\"1.0\", tk.END)\n",
    "        story_text.insert(tk.END, story)\n",
    "        \n",
    "        kannada_text.delete(\"1.0\", tk.END)\n",
    "        kannada_text.insert(tk.END, kannada_story)\n",
    "        \n",
    "        efficiency_label.config(text=f\"Time Taken: {time_taken:.2f}s\\nStory Length: {len(story.split())} words\\nEfficiency: {efficiency:.2f} words/s\\nBLEU: {bleu:.4f}\\nMETEOR: {meteor:.4f}\")\n",
    "\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "\n",
    "def read_kannada_story():\n",
    "    kannada_story = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    if kannada_story:\n",
    "        speak_kannada(kannada_story, \"IR FINAL\\\\audio_stories\\\\kannada_story.mp3\")\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator\")\n",
    "window.geometry(\"600x800\")\n",
    "\n",
    "image_label = Label(window)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "upload_button = Button(window, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack()\n",
    "\n",
    "caption_label = Label(window, text=\"Caption: \", wraplength=400, justify=\"center\")\n",
    "caption_label.pack(pady=10)\n",
    "\n",
    "story_text = Text(window, wrap=\"word\", width=60, height=10)\n",
    "story_text.pack(pady=10)\n",
    "\n",
    "kannada_text = Text(window, wrap=\"word\", width=60, height=10)\n",
    "kannada_text.pack(pady=10)\n",
    "\n",
    "efficiency_label = Label(window, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\")\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "read_english_button = Button(window, text=\"Read English Story\", command=read_english_story)\n",
    "read_english_button.pack(pady=5)\n",
    "\n",
    "read_kannada_button = Button(window, text=\"Read Kannada Story\", command=read_kannada_story)\n",
    "read_kannada_button.pack(pady=5)\n",
    "\n",
    "# New Label for Evaluation Metrics\n",
    "evaluation_label = Label(window, text=\"Evaluation Metrics: \", wraplength=400, justify=\"center\", font=(\"Arial\", 12, \"bold\"))\n",
    "evaluation_label.pack(pady=10)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Text, Scrollbar, Listbox\n",
    "import time\n",
    "import pyttsx3\n",
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import cv2\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "translator = GoogleTranslator(source=\"en\", target=\"kn\")\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "efficiency_metrics = {\n",
    "    \"image_processing_time\": 0,\n",
    "    \"story_generation_time\": 0,\n",
    "    \"translation_time\": 0,\n",
    "    \"audio_generation_time\": 0,\n",
    "    \"BLEU_score\": 0,\n",
    "    \"METEOR_score\": 0,\n",
    "    \"CIDEr_score\": 0,\n",
    "    \"SPICE_score\": 0\n",
    "}\n",
    "\n",
    "def compute_cider(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    A simplified CIDEr score calculation using TF-IDF weighting.\n",
    "    \"\"\"\n",
    "    ref_words = reference.lower().split()\n",
    "    hyp_words = hypothesis.lower().split()\n",
    "    \n",
    "    if not ref_words or not hyp_words:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute Term Frequency (TF)\n",
    "    ref_tf = {word: ref_words.count(word) / len(ref_words) for word in set(ref_words)}\n",
    "    hyp_tf = {word: hyp_words.count(word) / len(hyp_words)}\n",
    "    \n",
    "    # Compute Inverse Document Frequency (IDF)\n",
    "    all_words = set(ref_words + hyp_words)\n",
    "    idf = {word: np.log(1 + (1 / (1 + ref_words.count(word) + 1e-6))) for word in all_words}\n",
    "    \n",
    "    # Compute TF-IDF score\n",
    "    cider_score = sum(hyp_tf.get(word, 0) * idf.get(word, 0) for word in hyp_words)\n",
    "    \n",
    "    return round(cider_score, 4)\n",
    "\n",
    "def evaluate_caption(reference, hypothesis):\n",
    "    if not reference.strip() or not hypothesis.strip():\n",
    "        return\n",
    "    \n",
    "    # BLEU Score with Smoothing\n",
    "    smooth = SmoothingFunction().method1\n",
    "    efficiency_metrics[\"BLEU_score\"] = sentence_bleu([reference.split()], hypothesis.split(), smoothing_function=smooth)\n",
    "\n",
    "    # METEOR Score\n",
    "    efficiency_metrics[\"METEOR_score\"] = meteor_score([reference], hypothesis)\n",
    "\n",
    "    # CIDEr Score (Using simplified TF-IDF method)\n",
    "    efficiency_metrics[\"CIDEr_score\"] = compute_cider(reference, hypothesis)\n",
    "\n",
    "    # SPICE Score (Using SpaCy Semantic Similarity)\n",
    "    ref_doc = nlp(reference)\n",
    "    hyp_doc = nlp(hypothesis)\n",
    "    efficiency_metrics[\"SPICE_score\"] = ref_doc.similarity(hyp_doc)\n",
    "\n",
    "    update_efficiency_metrics()\n",
    "\n",
    "def update_efficiency_metrics():\n",
    "    metrics_text = (\n",
    "        f\"📸 Image Processing: {efficiency_metrics['image_processing_time']:.2f} sec\\n\"\n",
    "        f\"📖 Story Generation: {efficiency_metrics['story_generation_time']:.2f} sec\\n\"\n",
    "        f\"🌍 Translation: {efficiency_metrics['translation_time']:.2f} sec\\n\"\n",
    "        f\"🔊 Audio Generation: {efficiency_metrics['audio_generation_time']:.2f} sec\\n\"\n",
    "        f\"🔢 BLEU Score: {efficiency_metrics['BLEU_score']:.4f}\\n\"\n",
    "        f\"📊 METEOR Score: {efficiency_metrics['METEOR_score']:.4f}\\n\"\n",
    "        f\"📈 CIDEr Score: {efficiency_metrics['CIDEr_score']:.4f}\\n\"\n",
    "        f\"🧠 SPICE Score: {efficiency_metrics['SPICE_score']:.4f}\"\n",
    "    )\n",
    "    efficiency_label.config(text=metrics_text)\n",
    "\n",
    "\n",
    "def speak_kannada(text, filename=\"output.mp3\"):\n",
    "    tts = gTTS(text=text, lang=\"kn\")\n",
    "    tts.save(filename)\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def generate_caption(image):\n",
    "    start_time = time.time()\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    caption = blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"image_processing_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return caption\n",
    "\n",
    "def generate_story(caption, max_length=150):\n",
    "    start_time = time.time()\n",
    "\n",
    "    story_styles = [\n",
    "        \"A magical adventure unfolds where\",\n",
    "        \"A suspenseful tale emerges involving\",\n",
    "        \"A heartwarming story takes place as\",\n",
    "        \"An unexpected journey begins when\",\n",
    "        \"A dramatic event changes everything when\",\n",
    "        \"A mysterious secret is revealed when\",\n",
    "        \"A brave hero faces a great challenge when\",\n",
    "        \"A thrilling discovery is made as\",\n",
    "        \"A peaceful moment turns into an epic tale when\",\n",
    "        \"A legendary event occurs as\"\n",
    "    ]\n",
    "    random_prompt = random.choice(story_styles)\n",
    "    enriched_prompt = f\"The image shows {caption}. {random_prompt} unexpected events, emotions, and resolutions.\"\n",
    "\n",
    "    inputs = gpt_tokenizer.encode_plus(enriched_prompt, return_tensors=\"pt\", max_length=50, truncation=True).to(device)\n",
    "    outputs = gpt_model.generate(\n",
    "        inputs[\"input_ids\"], max_length=max_length, num_return_sequences=1,\n",
    "        no_repeat_ngram_size=3, temperature=1.2, top_k=50, top_p=0.90,\n",
    "        pad_token_id=gpt_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    story = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"story_generation_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return story\n",
    "\n",
    "def generate_multiple_stories(caption, num_stories=10):\n",
    "    return [generate_story(caption) for _ in range(num_stories)]\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = Image.open(file_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        caption = generate_caption(load_image(file_path))\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        stories = generate_multiple_stories(caption)\n",
    "\n",
    "        story_listbox.delete(0, tk.END)\n",
    "        for i in range(10):\n",
    "            story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "        efficiency_label.config(text=\"Generated 10 unique stories.\")\n",
    "\n",
    "        def on_story_select(event):\n",
    "            selected_index = story_listbox.curselection()\n",
    "            if selected_index:\n",
    "                index = selected_index[0]\n",
    "                story = stories[index]\n",
    "\n",
    "                start_time = time.time()\n",
    "                kannada_story = translator.translate(story)\n",
    "                efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "                update_efficiency_metrics()\n",
    "\n",
    "                story_text.delete(\"1.0\", tk.END)\n",
    "                story_text.insert(tk.END, story)\n",
    "\n",
    "                kannada_text.delete(\"1.0\", tk.END)\n",
    "                kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "        story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "        \n",
    "def capture_image():\n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "    ret, frame = cap.read()  # Capture a frame\n",
    "    cap.release()  # Release the webcam\n",
    "    \n",
    "    if ret:\n",
    "        img_path = \"captured_image.jpg\"\n",
    "        cv2.imwrite(img_path, frame)  # Save the captured image\n",
    "\n",
    "        # Load and display the captured image\n",
    "        img = Image.open(img_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        # Process the image\n",
    "        caption = generate_caption(load_image(img_path))\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        stories = generate_multiple_stories(caption)\n",
    "\n",
    "        story_listbox.delete(0, tk.END)\n",
    "        for i in range(10):\n",
    "            story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "        efficiency_label.config(text=\"Generated 10 unique stories.\")\n",
    "\n",
    "        def on_story_select(event):\n",
    "            selected_index = story_listbox.curselection()\n",
    "            if selected_index:\n",
    "                index = selected_index[0]\n",
    "                story = stories[index]\n",
    "\n",
    "                start_time = time.time()\n",
    "                kannada_story = translator.translate(story)\n",
    "                efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "                update_efficiency_metrics()\n",
    "\n",
    "                story_text.delete(\"1.0\", tk.END)\n",
    "                story_text.insert(tk.END, story)\n",
    "\n",
    "                kannada_text.delete(\"1.0\", tk.END)\n",
    "                kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "        story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "\n",
    "\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        start_time = time.time()\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "def read_kannada_story():\n",
    "    kannada_story = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    if kannada_story:\n",
    "        start_time = time.time()\n",
    "        speak_kannada(kannada_story)\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "# GUI Setup\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator\")\n",
    "window.geometry(\"900x800\")\n",
    "\n",
    "main_frame = tk.Frame(window)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "canvas = tk.Canvas(main_frame)\n",
    "scrollbar = Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "scrollable_frame = tk.Frame(canvas)\n",
    "scrollable_frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "image_label = Label(scrollable_frame)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "upload_button = Button(scrollable_frame, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack()\n",
    "\n",
    "capture_button = Button(scrollable_frame, text=\"Capture Image\", command=capture_image)\n",
    "capture_button.pack()\n",
    "\n",
    "caption_label = Label(scrollable_frame, text=\"Caption: \", wraplength=400, justify=\"center\")\n",
    "caption_label.pack(pady=10)\n",
    "\n",
    "\n",
    "\n",
    "story_listbox = Listbox(scrollable_frame, height=10)\n",
    "story_listbox.pack(pady=10)\n",
    "\n",
    "story_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "story_text.pack(pady=10)\n",
    "\n",
    "kannada_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "kannada_text.pack(pady=10)\n",
    "\n",
    "# 🏆 Efficiency Metrics Display\n",
    "efficiency_label = Label(scrollable_frame, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\", font=(\"Arial\", 12, \"bold\"))\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "\n",
    "\n",
    "read_english_button = Button(scrollable_frame, text=\"Read English Story\", command=read_english_story)\n",
    "read_english_button.pack(pady=5)\n",
    "\n",
    "read_kannada_button = Button(scrollable_frame, text=\"Read Kannada Story\", command=read_kannada_story)\n",
    "read_kannada_button.pack(pady=5)\n",
    "\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
