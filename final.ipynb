{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m  \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install PIL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "!pip install PIL\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Text, Scrollbar\n",
    "import time\n",
    "import pyttsx3  # For reading out the story\n",
    "from googletrans import Translator  # For translation\n",
    "\n",
    "# Initialize the BLIP captioning model and processor\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Load the GPT-2 model for story generation\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Initialize the text-to-speech engine\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "# Initialize the translator\n",
    "translator = Translator()\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def load_image(path):\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "# Generate a caption for the image\n",
    "def generate_caption(image):\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\")\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    caption = blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "# Generate a story based on the caption\n",
    "def generate_story(caption, max_length=100):\n",
    "    prompt = f\"{caption}. Once upon a time, \"\n",
    "    inputs = gpt_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = gpt_model.generate(\n",
    "        inputs, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7\n",
    "    )\n",
    "    story = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return story\n",
    "\n",
    "# Translate the story to Kannada\n",
    "def translate_to_kannada(text):\n",
    "    translation = translator.translate(text, src=\"en\", dest=\"kn\")\n",
    "    return translation.text\n",
    "\n",
    "# Main function to create a story from an image\n",
    "def image_to_story(path):\n",
    "    start_time = time.time()  # Start timing\n",
    "    image = load_image(path)\n",
    "    caption = generate_caption(image)\n",
    "    story = generate_story(caption)\n",
    "    end_time = time.time()  # End timing\n",
    "\n",
    "    # Calculate efficiency metrics\n",
    "    time_taken = end_time - start_time\n",
    "    story_length = len(story.split())  # Number of words in the story\n",
    "    efficiency = story_length / time_taken if time_taken > 0 else 0\n",
    "\n",
    "    return caption, story, time_taken, efficiency\n",
    "\n",
    "# Function to handle the image upload and display the story\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        # Display the selected image\n",
    "        img = Image.open(file_path).resize((300, 300))\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img)\n",
    "        image_label.image = img\n",
    "\n",
    "        # Generate caption, story, and efficiency metrics\n",
    "        caption, story, time_taken, efficiency = image_to_story(file_path)\n",
    "\n",
    "        # Translate the story to Kannada\n",
    "        story_in_kannada = translate_to_kannada(story)\n",
    "\n",
    "        # Display the caption and story\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        story_text.delete(\"1.0\", tk.END)\n",
    "        story_text.insert(tk.END, story)\n",
    "\n",
    "        # Display the translated story\n",
    "        kannada_text.delete(\"1.0\", tk.END)\n",
    "        kannada_text.insert(tk.END, story_in_kannada)\n",
    "\n",
    "        # Display efficiency metrics\n",
    "        efficiency_label.config(\n",
    "            text=f\"Time Taken: {time_taken:.2f} seconds\\nStory Length: {len(story.split())} words\\nEfficiency: {efficiency:.2f} words/second\"\n",
    "        )\n",
    "\n",
    "# Function to read out the English story\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "\n",
    "# Function to read out the Kannada story\n",
    "def read_kannada_story():\n",
    "    story_in_kannada = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    if story_in_kannada:\n",
    "        tts_engine.say(story_in_kannada)\n",
    "        tts_engine.runAndWait()\n",
    "\n",
    "# Set up the GUI window\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator with Kannada Translation\")\n",
    "window.geometry(\"600x800\")\n",
    "\n",
    "# Create a scrollable canvas\n",
    "main_frame = tk.Frame(window)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "canvas = tk.Canvas(main_frame)\n",
    "scrollbar = Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "scrollable_frame = tk.Frame(canvas)\n",
    "\n",
    "scrollable_frame.bind(\n",
    "    \"<Configure>\",\n",
    "    lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\"))\n",
    ")\n",
    "\n",
    "canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "# Add widgets to the scrollable frame\n",
    "image_label = Label(scrollable_frame)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "upload_button = Button(scrollable_frame, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack()\n",
    "\n",
    "caption_label = Label(scrollable_frame, text=\"Caption: \", wraplength=400, justify=\"center\")\n",
    "caption_label.pack(pady=10)\n",
    "\n",
    "story_text = Text(scrollable_frame, wrap=\"word\", width=60, height=10)\n",
    "story_text.pack(pady=10)\n",
    "\n",
    "kannada_text = Text(scrollable_frame, wrap=\"word\", width=60, height=10)\n",
    "kannada_text.pack(pady=10)\n",
    "\n",
    "efficiency_label = Label(scrollable_frame, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\")\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "read_english_button = Button(scrollable_frame, text=\"Read English Story\", command=read_english_story)\n",
    "read_english_button.pack(pady=5)\n",
    "\n",
    "read_kannada_button = Button(scrollable_frame, text=\"Read Kannada Story\", command=read_kannada_story)\n",
    "read_kannada_button.pack(pady=5)\n",
    "\n",
    "# Run the GUI loop\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansl6\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Text, Scrollbar\n",
    "import time\n",
    "import pyttsx3\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "tts_engine = pyttsx3.init()\n",
    "translator = GoogleTranslator(source=\"en\", target=\"kn\")\n",
    "\n",
    "# Load and preprocess image\n",
    "def load_image(path):\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "# Generate caption for the image\n",
    "def generate_caption(image):\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    caption = blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "# Generate a story based on an enriched prompt\n",
    "def generate_story(caption, max_length=150):\n",
    "    # Enrich the caption for better story context\n",
    "    enriched_prompt = f\"The image shows {caption}. In this scene, \"\n",
    "    enriched_prompt += \"a magical story unfolds involving unexpected events, emotions, and resolutions.\"\n",
    "    inputs = gpt_tokenizer.encode(enriched_prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    outputs = gpt_model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    story = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return story\n",
    "\n",
    "# Translate the story to Kannada\n",
    "def translate_to_kannada(text):\n",
    "    return translator.translate(text)\n",
    "\n",
    "# Main function to generate caption, story, and efficiency metrics\n",
    "def image_to_story(path):\n",
    "    start_time = time.time()\n",
    "    image = load_image(path)\n",
    "    caption = generate_caption(image)\n",
    "    story = generate_story(caption)\n",
    "    time_taken = time.time() - start_time\n",
    "    story_length = len(story.split())\n",
    "    efficiency = story_length / time_taken if time_taken > 0 else 0\n",
    "    return caption, story, time_taken, efficiency\n",
    "\n",
    "# Handle the upload image process\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = Image.open(file_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        caption, story, time_taken, efficiency = image_to_story(file_path)\n",
    "        kannada_story = translate_to_kannada(story)\n",
    "\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        story_text.delete(\"1.0\", tk.END)\n",
    "        story_text.insert(tk.END, story)\n",
    "        kannada_text.delete(\"1.0\", tk.END)\n",
    "        kannada_text.insert(tk.END, kannada_story)\n",
    "        efficiency_label.config(\n",
    "            text=f\"Time Taken: {time_taken:.2f}s\\nStory Length: {len(story.split())} words\\nEfficiency: {efficiency:.2f} words/s\"\n",
    "        )\n",
    "\n",
    "# Read English story\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "\n",
    "# Read Kannada story\n",
    "def read_kannada_story():\n",
    "    kannada_story = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    if kannada_story:\n",
    "        tts_engine.say(kannada_story)\n",
    "        tts_engine.runAndWait()\n",
    "\n",
    "# GUI Setup\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator\")\n",
    "window.geometry(\"600x800\")\n",
    "\n",
    "main_frame = tk.Frame(window)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "canvas = tk.Canvas(main_frame)\n",
    "scrollbar = Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "scrollable_frame = tk.Frame(canvas)\n",
    "\n",
    "scrollable_frame.bind(\n",
    "    \"<Configure>\",\n",
    "    lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\"))\n",
    ")\n",
    "\n",
    "canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "image_label = Label(scrollable_frame)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "upload_button = Button(scrollable_frame, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack()\n",
    "\n",
    "caption_label = Label(scrollable_frame, text=\"Caption: \", wraplength=400, justify=\"center\")\n",
    "caption_label.pack(pady=10)\n",
    "\n",
    "story_text = Text(scrollable_frame, wrap=\"word\", width=60, height=10)\n",
    "story_text.pack(pady=10)\n",
    "\n",
    "kannada_text = Text(scrollable_frame, wrap=\"word\", width=60, height=10)\n",
    "kannada_text.pack(pady=10)\n",
    "\n",
    "efficiency_label = Label(scrollable_frame, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\")\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "read_english_button = Button(scrollable_frame, text=\"Read English Story\", command=read_english_story)\n",
    "read_english_button.pack(pady=5)\n",
    "\n",
    "read_kannada_button = Button(scrollable_frame, text=\"Read Kannada Story\", command=read_kannada_story)\n",
    "read_kannada_button.pack(pady=5)\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansl6\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "c:\\Users\\ansl6\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Text, Scrollbar\n",
    "import time\n",
    "import pyttsx3\n",
    "from deep_translator import GoogleTranslator\n",
    "import sys\n",
    "import os\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "translator = GoogleTranslator(source=\"en\", target=\"kn\")\n",
    "\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "def speak_kannada(text, filename=\"output.mp3\"):\n",
    "    tts = gTTS(text=text, lang=\"kn\")\n",
    "    tts.save(filename)\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "# Load and preprocess image\n",
    "def load_image(path):\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "# Generate caption for the image\n",
    "def generate_caption(image):\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    caption = blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "# Generate a story based on an enriched prompt\n",
    "def generate_story(caption, max_length=150):\n",
    "    enriched_prompt = f\"The image shows {caption}. In this scene, a magical story unfolds involving unexpected events, emotions, and resolutions.\"\n",
    "    inputs = gpt_tokenizer.encode(enriched_prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "    \n",
    "    outputs = gpt_model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    story = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return story\n",
    "\n",
    "# Translate the story to Kannada\n",
    "def translate_to_kannada(text):\n",
    "    return translator.translate(text)\n",
    "\n",
    "# Main function to generate caption, story, and efficiency metrics\n",
    "def image_to_story(path):\n",
    "    start_time = time.time()\n",
    "    image = load_image(path)\n",
    "    caption = generate_caption(image)\n",
    "    story = generate_story(caption)\n",
    "    time_taken = time.time() - start_time\n",
    "    story_length = len(story.split())\n",
    "    efficiency = story_length / time_taken if time_taken > 0 else 0\n",
    "    return caption, story, time_taken, efficiency\n",
    "\n",
    "# Handle the upload image process\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = Image.open(file_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        caption, story, time_taken, efficiency = image_to_story(file_path)\n",
    "        kannada_story = translate_to_kannada(story)\n",
    "\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        story_text.delete(\"1.0\", tk.END)\n",
    "        story_text.insert(tk.END, story)\n",
    "        kannada_text.delete(\"1.0\", tk.END)\n",
    "        kannada_text.insert(tk.END, kannada_story)\n",
    "        efficiency_label.config(\n",
    "            text=f\"Time Taken: {time_taken:.2f}s\\nStory Length: {len(story.split())} words\\nEfficiency: {efficiency:.2f} words/s\"\n",
    "        )\n",
    "\n",
    "# Read English story\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "\n",
    "# Read Kannada story\n",
    "def read_kannada_story():\n",
    "    kannada_story = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    if kannada_story:\n",
    "        speak_kannada(kannada_story)\n",
    "\n",
    "# GUI Setup\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator\")\n",
    "window.geometry(\"600x800\")\n",
    "\n",
    "main_frame = tk.Frame(window)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "canvas = tk.Canvas(main_frame)\n",
    "scrollbar = Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "scrollable_frame = tk.Frame(canvas)\n",
    "\n",
    "scrollable_frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "image_label = Label(scrollable_frame)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "upload_button = Button(scrollable_frame, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack()\n",
    "\n",
    "caption_label = Label(scrollable_frame, text=\"Caption: \", wraplength=400, justify=\"center\")\n",
    "caption_label.pack(pady=10)\n",
    "\n",
    "story_text = Text(scrollable_frame, wrap=\"word\", width=60, height=10)\n",
    "story_text.pack(pady=10)\n",
    "\n",
    "kannada_text = Text(scrollable_frame, wrap=\"word\", width=60, height=10)\n",
    "kannada_text.pack(pady=10)\n",
    "\n",
    "efficiency_label = Label(scrollable_frame, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\")\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "read_english_button = Button(scrollable_frame, text=\"Read English Story\", command=read_english_story)\n",
    "read_english_button.pack(pady=5)\n",
    "\n",
    "read_kannada_button = Button(scrollable_frame, text=\"Read Kannada Story\", command=read_kannada_story)\n",
    "read_kannada_button.pack(pady=5)\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Text, Scrollbar, Listbox\n",
    "import time\n",
    "import pyttsx3\n",
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "translator = GoogleTranslator(source=\"en\", target=\"kn\")\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "# Dictionary to store efficiency metrics\n",
    "efficiency_metrics = {\n",
    "    \"image_processing_time\": 0,\n",
    "    \"story_generation_time\": 0,\n",
    "    \"translation_time\": 0,\n",
    "    \"audio_generation_time\": 0\n",
    "}\n",
    "\n",
    "def update_efficiency_metrics():\n",
    "    \"\"\"\n",
    "    Updates efficiency metrics on the GUI.\n",
    "    \"\"\"\n",
    "    metrics_text = (\n",
    "        f\"üì∏ Image Processing: {efficiency_metrics['image_processing_time']:.2f} sec\\n\"\n",
    "        f\"üìñ Story Generation: {efficiency_metrics['story_generation_time']:.2f} sec\\n\"\n",
    "        f\"üåç Translation: {efficiency_metrics['translation_time']:.2f} sec\\n\"\n",
    "        f\"üîä Audio Generation: {efficiency_metrics['audio_generation_time']:.2f} sec\"\n",
    "    )\n",
    "    efficiency_label.config(text=metrics_text)\n",
    "\n",
    "def speak_kannada(text, filename=\"output.mp3\"):\n",
    "    tts = gTTS(text=text, lang=\"kn\")\n",
    "    tts.save(filename)\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def generate_caption(image):\n",
    "    start_time = time.time()\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    caption = blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"image_processing_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return caption\n",
    "\n",
    "def generate_story(caption, max_length=150):\n",
    "    start_time = time.time()\n",
    "\n",
    "    story_styles = [\n",
    "        \"A magical adventure unfolds where\",\n",
    "        \"A suspenseful tale emerges involving\",\n",
    "        \"A heartwarming story takes place as\",\n",
    "        \"An unexpected journey begins when\",\n",
    "        \"A dramatic event changes everything when\",\n",
    "        \"A mysterious secret is revealed when\",\n",
    "        \"A brave hero faces a great challenge when\",\n",
    "        \"A thrilling discovery is made as\",\n",
    "        \"A peaceful moment turns into an epic tale when\",\n",
    "        \"A legendary event occurs as\"\n",
    "    ]\n",
    "    random_prompt = random.choice(story_styles)\n",
    "    enriched_prompt = f\"The image shows {caption}. {random_prompt} unexpected events, emotions, and resolutions.\"\n",
    "\n",
    "    inputs = gpt_tokenizer.encode_plus(enriched_prompt, return_tensors=\"pt\", max_length=50, truncation=True).to(device)\n",
    "    outputs = gpt_model.generate(\n",
    "        inputs[\"input_ids\"], max_length=max_length, num_return_sequences=1,\n",
    "        no_repeat_ngram_size=3, temperature=1.2, top_k=50, top_p=0.90,\n",
    "        pad_token_id=gpt_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    story = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"story_generation_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return story\n",
    "\n",
    "def generate_multiple_stories(caption, num_stories=10):\n",
    "    return [generate_story(caption) for _ in range(num_stories)]\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = Image.open(file_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        caption = generate_caption(load_image(file_path))\n",
    "        stories = generate_multiple_stories(caption)\n",
    "\n",
    "        story_listbox.delete(0, tk.END)\n",
    "        for i in range(10):\n",
    "            story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "        efficiency_label.config(text=\"Generated 10 unique stories.\")\n",
    "\n",
    "        def on_story_select(event):\n",
    "            selected_index = story_listbox.curselection()\n",
    "            if selected_index:\n",
    "                index = selected_index[0]\n",
    "                story = stories[index]\n",
    "\n",
    "                start_time = time.time()\n",
    "                kannada_story = translator.translate(story)\n",
    "                efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "                update_efficiency_metrics()\n",
    "\n",
    "                story_text.delete(\"1.0\", tk.END)\n",
    "                story_text.insert(tk.END, story)\n",
    "\n",
    "                kannada_text.delete(\"1.0\", tk.END)\n",
    "                kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "        story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        start_time = time.time()\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "def read_kannada_story():\n",
    "    kannada_story = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    if kannada_story:\n",
    "        start_time = time.time()\n",
    "        speak_kannada(kannada_story)\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "# GUI Setup\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator\")\n",
    "window.geometry(\"900x800\")\n",
    "\n",
    "main_frame = tk.Frame(window)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "canvas = tk.Canvas(main_frame)\n",
    "scrollbar = Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "scrollable_frame = tk.Frame(canvas)\n",
    "scrollable_frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "image_label = Label(scrollable_frame)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "upload_button = Button(scrollable_frame, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack()\n",
    "\n",
    "story_listbox = Listbox(scrollable_frame, height=10)\n",
    "story_listbox.pack(pady=10)\n",
    "\n",
    "story_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "story_text.pack(pady=10)\n",
    "\n",
    "kannada_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "kannada_text.pack(pady=10)\n",
    "\n",
    "# üèÜ Efficiency Metrics Display\n",
    "efficiency_label = Label(scrollable_frame, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\", font=(\"Arial\", 12, \"bold\"))\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "read_english_button = Button(scrollable_frame, text=\"Read English Story\", command=read_english_story)\n",
    "read_english_button.pack(pady=5)\n",
    "\n",
    "read_kannada_button = Button(scrollable_frame, text=\"Read Kannada Story\", command=read_kannada_story)\n",
    "read_kannada_button.pack(pady=5)\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Text, Scrollbar, Listbox\n",
    "import time\n",
    "import pyttsx3\n",
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import cv2\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "translator = GoogleTranslator(source=\"en\", target=\"kn\")\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "# Dictionary to store efficiency metrics\n",
    "efficiency_metrics = {\n",
    "    \"image_processing_time\": 0,\n",
    "    \"story_generation_time\": 0,\n",
    "    \"translation_time\": 0,\n",
    "    \"audio_generation_time\": 0\n",
    "}\n",
    "\n",
    "def update_efficiency_metrics():\n",
    "    \"\"\"\n",
    "    Updates efficiency metrics on the GUI.\n",
    "    \"\"\"\n",
    "    metrics_text = (\n",
    "        f\"üì∏ Image Processing: {efficiency_metrics['image_processing_time']:.2f} sec\\n\"\n",
    "        f\"üìñ Story Generation: {efficiency_metrics['story_generation_time']:.2f} sec\\n\"\n",
    "        f\"üåç Translation: {efficiency_metrics['translation_time']:.2f} sec\\n\"\n",
    "        f\"üîä Audio Generation: {efficiency_metrics['audio_generation_time']:.2f} sec\"\n",
    "    )\n",
    "    efficiency_label.config(text=metrics_text)\n",
    "\n",
    "def speak_kannada(text, filename=\"output.mp3\"):\n",
    "    tts = gTTS(text=text, lang=\"kn\")\n",
    "    tts.save(filename)\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def generate_caption(image):\n",
    "    start_time = time.time()\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    caption = blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"image_processing_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return caption\n",
    "\n",
    "def generate_story(caption, max_length=150):\n",
    "    start_time = time.time()\n",
    "\n",
    "    story_styles = [\n",
    "        \"A magical adventure unfolds where\",\n",
    "        \"A suspenseful tale emerges involving\",\n",
    "        \"A heartwarming story takes place as\",\n",
    "        \"An unexpected journey begins when\",\n",
    "        \"A dramatic event changes everything when\",\n",
    "        \"A mysterious secret is revealed when\",\n",
    "        \"A brave hero faces a great challenge when\",\n",
    "        \"A thrilling discovery is made as\",\n",
    "        \"A peaceful moment turns into an epic tale when\",\n",
    "        \"A legendary event occurs as\"\n",
    "    ]\n",
    "    random_prompt = random.choice(story_styles)\n",
    "    enriched_prompt = f\"The image shows {caption}. {random_prompt} unexpected events, emotions, and resolutions.\"\n",
    "\n",
    "    inputs = gpt_tokenizer.encode_plus(enriched_prompt, return_tensors=\"pt\", max_length=50, truncation=True).to(device)\n",
    "    outputs = gpt_model.generate(\n",
    "        inputs[\"input_ids\"], max_length=max_length, num_return_sequences=1,\n",
    "        no_repeat_ngram_size=3, temperature=1.2, top_k=50, top_p=0.90,\n",
    "        pad_token_id=gpt_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    story = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"story_generation_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return story\n",
    "\n",
    "def generate_multiple_stories(caption, num_stories=10):\n",
    "    return [generate_story(caption) for _ in range(num_stories)]\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = Image.open(file_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        caption = generate_caption(load_image(file_path))\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        stories = generate_multiple_stories(caption)\n",
    "\n",
    "        story_listbox.delete(0, tk.END)\n",
    "        for i in range(10):\n",
    "            story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "        efficiency_label.config(text=\"Generated 10 unique stories.\")\n",
    "\n",
    "        def on_story_select(event):\n",
    "            selected_index = story_listbox.curselection()\n",
    "            if selected_index:\n",
    "                index = selected_index[0]\n",
    "                story = stories[index]\n",
    "\n",
    "                start_time = time.time()\n",
    "                kannada_story = translator.translate(story)\n",
    "                efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "                update_efficiency_metrics()\n",
    "\n",
    "                story_text.delete(\"1.0\", tk.END)\n",
    "                story_text.insert(tk.END, story)\n",
    "\n",
    "                kannada_text.delete(\"1.0\", tk.END)\n",
    "                kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "        story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "        \n",
    "def capture_image():\n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "    ret, frame = cap.read()  # Capture a frame\n",
    "    cap.release()  # Release the webcam\n",
    "    \n",
    "    if ret:\n",
    "        img_path = \"captured_image.jpg\"\n",
    "        cv2.imwrite(img_path, frame)  # Save the captured image\n",
    "\n",
    "        # Load and display the captured image\n",
    "        img = Image.open(img_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        # Process the image\n",
    "        caption = generate_caption(load_image(img_path))\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        stories = generate_multiple_stories(caption)\n",
    "\n",
    "        story_listbox.delete(0, tk.END)\n",
    "        for i in range(10):\n",
    "            story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "        efficiency_label.config(text=\"Generated 10 unique stories.\")\n",
    "\n",
    "        def on_story_select(event):\n",
    "            selected_index = story_listbox.curselection()\n",
    "            if selected_index:\n",
    "                index = selected_index[0]\n",
    "                story = stories[index]\n",
    "\n",
    "                start_time = time.time()\n",
    "                kannada_story = translator.translate(story)\n",
    "                efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "                update_efficiency_metrics()\n",
    "\n",
    "                story_text.delete(\"1.0\", tk.END)\n",
    "                story_text.insert(tk.END, story)\n",
    "\n",
    "                kannada_text.delete(\"1.0\", tk.END)\n",
    "                kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "        story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "\n",
    "\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        start_time = time.time()\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "def read_kannada_story():\n",
    "    kannada_story = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    if kannada_story:\n",
    "        start_time = time.time()\n",
    "        speak_kannada(kannada_story)\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "# GUI Setup\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator\")\n",
    "window.geometry(\"900x800\")\n",
    "\n",
    "main_frame = tk.Frame(window)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "canvas = tk.Canvas(main_frame)\n",
    "scrollbar = Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "scrollable_frame = tk.Frame(canvas)\n",
    "scrollable_frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "image_label = Label(scrollable_frame)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "upload_button = Button(scrollable_frame, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack()\n",
    "\n",
    "capture_button = Button(scrollable_frame, text=\"Capture Image\", command=capture_image)\n",
    "capture_button.pack()\n",
    "\n",
    "caption_label = Label(scrollable_frame, text=\"Caption: \", wraplength=400, justify=\"center\")\n",
    "caption_label.pack(pady=10)\n",
    "\n",
    "story_listbox = Listbox(scrollable_frame, height=10)\n",
    "story_listbox.pack(pady=10)\n",
    "\n",
    "story_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "story_text.pack(pady=10)\n",
    "\n",
    "kannada_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "kannada_text.pack(pady=10)\n",
    "\n",
    "# üèÜ Efficiency Metrics Display\n",
    "efficiency_label = Label(scrollable_frame, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\", font=(\"Arial\", 12, \"bold\"))\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "read_english_button = Button(scrollable_frame, text=\"Read English Story\", command=read_english_story)\n",
    "read_english_button.pack(pady=5)\n",
    "\n",
    "read_kannada_button = Button(scrollable_frame, text=\"Read Kannada Story\", command=read_kannada_story)\n",
    "read_kannada_button.pack(pady=5)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Stories: ['The image shows a tiger in the woods. A heartwarming story takes place as unexpected events, emotions, and resolutions.\\n\\nThe story begins with a tiger named \"Tiger\" who is a member of the \"Tigers of the Forest\" (Tigers in the Forest). He is a young man who has been living in the forest for a long time. He is the only tiger in his family. He has been a member for over a year and has been in the forests for over two years. He was a member in the past and has always been a tiger. He had a heart of gold and was a tiger\\'s protector. He wanted to be a tiger and was willing to sacrifice his life for the tiger.\\n.\\n', \"The image shows a tiger in the woods. A dramatic event changes everything when unexpected events, emotions, and resolutions.\\n\\nThe tiger is a very powerful animal. It is a powerful animal that can be used to manipulate people. It can be a powerful creature that can manipulate people and people can be manipulated by it. It's a powerful beast that can control people.\\n.\\n (The image is a tiger with a large head and a large body. The tiger is in the forest. The image shows the tiger in a forest. A scene of the tiger is shown. The scene of a tiger is seen. The animal is in a tree. The tree is in front of the tree. A tiger is standing in front. The forest is\", \"The image shows a tiger in the woods. A thrilling discovery is made as unexpected events, emotions, and resolutions.\\n\\nThe tiger is a large, black-eyed, black bear with a long, black tail. It is a very large animal, and it is very difficult to identify. It has a long tail, and its body is very long. It can be seen from the ground. It's very large, and very difficult for humans to identify it.\\n.\\n (The image is a tiger with a short, black, tail. A fascinating discovery is found as unexpected circumstances, emotions and resolutions are made. The tiger is an extremely large, white-eyed black bear, with a very long, white tail. The animal is\", 'The image shows a tiger in the woods. A legendary event occurs as unexpected events, emotions, and resolutions.\\n\\nThe image is a composite of the two images. The tiger is in the forest, and the tiger is standing in the middle of the forest. The image shows the tiger in a position to be seen. The two images are the same.\\n.\\n (The image of the tiger, which is in a tree, is in an image of a tiger. The images are different. The picture is a different image. The same image is in another image.\\n, which are different images.\\n: The image of an elephant in the wild. The elephant is in front of the image of another elephant. The elephants are in', 'The image shows a tiger in the woods. A legendary event occurs as unexpected events, emotions, and resolutions.\\n\\nThe image is a composite of the two images. The tiger is in the forest, and the tiger is standing in the middle of the forest. The image shows the tiger in a position to be seen. The two images are the same.\\n.\\n (The image of the tiger, which is in a tree, is in an image of a tiger. The images are different. The picture is a different image. The same image is in another image.\\n, which are different images.\\n: The image of an elephant in the wild. The elephant is in front of the image of another elephant. The elephants are in', 'The image shows a tiger in the woods. A peaceful moment turns into an epic tale when unexpected events, emotions, and resolutions.\\n\\nThe image is a composite of the two images. The tiger is in the forest, and the man is in a forest. The man is standing in the middle of the forest.\\n.\\n (Photo: Wikimedia Commons)\\n\\n.', 'The image shows a tiger in the woods. A peaceful moment turns into an epic tale when unexpected events, emotions, and resolutions.\\n\\nThe image is a composite of the two images. The tiger is in the forest, and the man is in a forest. The man is standing in the middle of the forest.\\n.\\n (Photo: Wikimedia Commons)\\n\\n.', 'The image shows a tiger in the woods. A peaceful moment turns into an epic tale when unexpected events, emotions, and resolutions.\\n\\nThe image is a composite of the two images. The tiger is in the forest, and the man is in a forest. The man is standing in the middle of the forest.\\n.\\n (Photo: Wikimedia Commons)\\n\\n.', 'The image shows a tiger in the woods. A heartwarming story takes place as unexpected events, emotions, and resolutions.\\n\\nThe story begins with a tiger named \"Tiger\" who is a member of the \"Tigers of the Forest\" (Tigers in the Forest). He is a young man who has been living in the forest for a long time. He is the only tiger in his family. He has been a member for over a year and has been in the forests for over two years. He was a member in the past and has always been a tiger. He had a heart of gold and was a tiger\\'s protector. He wanted to be a tiger and was willing to sacrifice his life for the tiger.\\n.\\n', 'The image shows a tiger in the woods. A peaceful moment turns into an epic tale when unexpected events, emotions, and resolutions.\\n\\nThe image is a composite of the two images. The tiger is in the forest, and the man is in a forest. The man is standing in the middle of the forest.\\n.\\n (Photo: Wikimedia Commons)\\n\\n.']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Text, Scrollbar, Listbox\n",
    "import time\n",
    "import pyttsx3\n",
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "translator = GoogleTranslator(source=\"en\", target=\"kn\")\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "# Dictionary to store efficiency metrics\n",
    "efficiency_metrics = {\n",
    "    \"image_processing_time\": 0,\n",
    "    \"story_generation_time\": 0,\n",
    "    \"translation_time\": 0,\n",
    "    \"audio_generation_time\": 0\n",
    "}\n",
    "\n",
    "def update_efficiency_metrics():\n",
    "    \"\"\"\n",
    "    Updates efficiency metrics on the GUI.\n",
    "    \"\"\"\n",
    "    metrics_text = (\n",
    "        f\"üì∏ Image Processing: {efficiency_metrics['image_processing_time']:.2f} sec\\n\"\n",
    "        f\"üìñ Story Generation: {efficiency_metrics['story_generation_time']:.2f} sec\\n\"\n",
    "        f\"üåç Translation: {efficiency_metrics['translation_time']:.2f} sec\\n\"\n",
    "        f\"üîä Audio Generation: {efficiency_metrics['audio_generation_time']:.2f} sec\"\n",
    "    )\n",
    "    efficiency_label.config(text=metrics_text)\n",
    "\n",
    "def speak_kannada(text, filename=\"output.mp3\"):\n",
    "    tts = gTTS(text=text, lang=\"kn\")\n",
    "    tts.save(filename)\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def generate_caption(image):\n",
    "    start_time = time.time()\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    caption = blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"image_processing_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return caption\n",
    "\n",
    "def generate_story(caption, max_length=150):\n",
    "    start_time = time.time()\n",
    "\n",
    "    story_styles = [\n",
    "        \"A magical adventure unfolds where\",\n",
    "        \"A suspenseful tale emerges involving\",\n",
    "        \"A heartwarming story takes place as\",\n",
    "        \"An unexpected journey begins when\",\n",
    "        \"A dramatic event changes everything when\",\n",
    "        \"A mysterious secret is revealed when\",\n",
    "        \"A brave hero faces a great challenge when\",\n",
    "        \"A thrilling discovery is made as\",\n",
    "        \"A peaceful moment turns into an epic tale when\",\n",
    "        \"A legendary event occurs as\"\n",
    "    ]\n",
    "    random_prompt = random.choice(story_styles)\n",
    "    enriched_prompt = f\"The image shows {caption}. {random_prompt} unexpected events, emotions, and resolutions.\"\n",
    "\n",
    "    inputs = gpt_tokenizer.encode_plus(enriched_prompt, return_tensors=\"pt\", max_length=50, truncation=True).to(device)\n",
    "    outputs = gpt_model.generate(\n",
    "        inputs[\"input_ids\"], max_length=max_length, num_return_sequences=1,\n",
    "        no_repeat_ngram_size=3, temperature=1.2, top_k=50, top_p=0.90,\n",
    "        pad_token_id=gpt_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    story = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"story_generation_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return story\n",
    "\n",
    "def generate_multiple_stories(caption, num_stories=10):\n",
    "    return [generate_story(caption) for _ in range(num_stories)]\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = Image.open(file_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        caption = generate_caption(load_image(file_path))\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        stories = generate_multiple_stories(caption)\n",
    "\n",
    "        print(\"Generated Stories:\", stories)\n",
    "\n",
    "        story_listbox.delete(0, tk.END)\n",
    "        for i in range(10):\n",
    "            story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "        efficiency_label.config(text=\"Generated 10 unique stories.\")\n",
    "\n",
    "        def on_story_select(event):\n",
    "            selected_index = story_listbox.curselection()\n",
    "            if selected_index:\n",
    "                index = selected_index[0]\n",
    "                story = stories[index]\n",
    "\n",
    "                start_time = time.time()\n",
    "                kannada_story = translator.translate(story)\n",
    "                efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "                update_efficiency_metrics()\n",
    "\n",
    "                story_text.delete(\"1.0\", tk.END)\n",
    "                story_text.insert(tk.END, story)\n",
    "\n",
    "                kannada_text.delete(\"1.0\", tk.END)\n",
    "                kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "        story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "        \n",
    "        save_button = Button(scrollable_frame, text=\"Save All Stories\", command=lambda: save_all_stories(stories))\n",
    "        save_button.pack(pady=5)\n",
    "\n",
    "def capture_image():\n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "    ret, frame = cap.read()  # Capture a frame\n",
    "    cap.release()  # Release the webcam\n",
    "    \n",
    "    if ret:\n",
    "        img_path = \"captured_image.jpg\"\n",
    "        cv2.imwrite(img_path, frame)  # Save the captured image\n",
    "\n",
    "        # Load and display the captured image\n",
    "        img = Image.open(img_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        # Process the image\n",
    "        caption = generate_caption(load_image(img_path))\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        stories = generate_multiple_stories(caption)\n",
    "\n",
    "        story_listbox.delete(0, tk.END)\n",
    "        for i in range(10):\n",
    "            story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "        efficiency_label.config(text=\"Generated 10 unique stories.\")\n",
    "\n",
    "        def on_story_select(event):\n",
    "            selected_index = story_listbox.curselection()\n",
    "            if selected_index:\n",
    "                index = selected_index[0]\n",
    "                story = stories[index]\n",
    "\n",
    "                start_time = time.time()\n",
    "                kannada_story = translator.translate(story)\n",
    "                efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "                update_efficiency_metrics()\n",
    "\n",
    "                story_text.delete(\"1.0\", tk.END)\n",
    "                story_text.insert(tk.END, story)\n",
    "\n",
    "                kannada_text.delete(\"1.0\", tk.END)\n",
    "                kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "        story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "\n",
    "\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        start_time = time.time()\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "def read_kannada_story():\n",
    "    kannada_story = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    if kannada_story:\n",
    "        start_time = time.time()\n",
    "        speak_kannada(kannada_story)\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "def save_story(story, kannada_story, story_index):\n",
    "    \"\"\"\n",
    "    Saves the generated stories in one folder and audio files in another.\n",
    "    \"\"\"\n",
    "    # Create directories to store the stories and audio files if they don't exist\n",
    "    story_dir = \"generated_stories\"\n",
    "    audio_dir = \"generated_audio\"\n",
    "    os.makedirs(story_dir, exist_ok=True)\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "    \n",
    "    # Define file paths for text files\n",
    "    english_text_path = os.path.join(story_dir, f\"story_{story_index}_english.txt\")\n",
    "    kannada_text_path = os.path.join(story_dir, f\"story_{story_index}_kannada.txt\")\n",
    "    \n",
    "    # Define file paths for audio files\n",
    "    english_audio_path = os.path.join(audio_dir, f\"story_{story_index}_english.mp3\")\n",
    "    kannada_audio_path = os.path.join(audio_dir, f\"story_{story_index}_kannada.mp3\")\n",
    "    \n",
    "    # Save text files\n",
    "    with open(english_text_path, \"w\", encoding=\"utf-8\") as eng_file:\n",
    "        eng_file.write(story)\n",
    "    \n",
    "    with open(kannada_text_path, \"w\", encoding=\"utf-8\") as kan_file:\n",
    "        kan_file.write(kannada_story)\n",
    "    \n",
    "    # Save audio files\n",
    "    tts_eng = gTTS(text=story, lang=\"en\")\n",
    "    tts_eng.save(english_audio_path)\n",
    "    \n",
    "    tts_kan = gTTS(text=kannada_story, lang=\"kn\")\n",
    "    tts_kan.save(kannada_audio_path)\n",
    "\n",
    "def save_all_stories(stories):\n",
    "    \"\"\"\n",
    "    Saves all generated stories along with their Kannada translations and audio.\n",
    "    \"\"\"\n",
    "    for i, story in enumerate(stories):\n",
    "        start_time = time.time()\n",
    "        kannada_story = translator.translate(story)\n",
    "        efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "        save_story(story, kannada_story, i + 1)\n",
    "\n",
    "\n",
    "# GUI Setup\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator\")\n",
    "window.geometry(\"900x800\")\n",
    "\n",
    "main_frame = tk.Frame(window)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "canvas = tk.Canvas(main_frame)\n",
    "scrollbar = Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "scrollable_frame = tk.Frame(canvas)\n",
    "scrollable_frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "image_label = Label(scrollable_frame)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "upload_button = Button(scrollable_frame, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack()\n",
    "\n",
    "capture_button = Button(scrollable_frame, text=\"Capture Image\", command=capture_image)\n",
    "capture_button.pack()\n",
    "\n",
    "caption_label = Label(scrollable_frame, text=\"Caption: \", wraplength=400, justify=\"center\")\n",
    "caption_label.pack(pady=10)\n",
    "\n",
    "story_listbox = Listbox(scrollable_frame, height=10)\n",
    "story_listbox.pack(pady=10)\n",
    "\n",
    "story_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "story_text.pack(pady=10)\n",
    "\n",
    "kannada_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "kannada_text.pack(pady=10)\n",
    "\n",
    "# üèÜ Efficiency Metrics Display\n",
    "efficiency_label = Label(scrollable_frame, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\", font=(\"Arial\", 12, \"bold\"))\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "read_english_button = Button(scrollable_frame, text=\"Read English Story\", command=read_english_story)\n",
    "read_english_button.pack(pady=5)\n",
    "\n",
    "read_kannada_button = Button(scrollable_frame, text=\"Read Kannada Story\", command=read_kannada_story)\n",
    "read_kannada_button.pack(pady=5)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Text, Scrollbar, Listbox\n",
    "import time\n",
    "import pyttsx3\n",
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "translator = GoogleTranslator(source=\"en\", target=\"kn\")\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "# Dictionary to store efficiency metrics\n",
    "efficiency_metrics = {\n",
    "    \"image_processing_time\": 0,\n",
    "    \"story_generation_time\": 0,\n",
    "    \"translation_time\": 0,\n",
    "    \"audio_generation_time\": 0\n",
    "}\n",
    "\n",
    "def update_efficiency_metrics():\n",
    "    \"\"\"\n",
    "    Updates efficiency metrics on the GUI.\n",
    "    \"\"\"\n",
    "    metrics_text = (\n",
    "        f\"üì∏ Image Processing: {efficiency_metrics['image_processing_time']:.2f} sec\\n\"\n",
    "        f\"üìñ Story Generation: {efficiency_metrics['story_generation_time']:.2f} sec\\n\"\n",
    "        f\"üåç Translation: {efficiency_metrics['translation_time']:.2f} sec\\n\"\n",
    "        f\"üîä Audio Generation: {efficiency_metrics['audio_generation_time']:.2f} sec\"\n",
    "    )\n",
    "    efficiency_label.config(text=metrics_text)\n",
    "\n",
    "def speak_kannada(text, filename=\"output.mp3\"):\n",
    "    tts = gTTS(text=text, lang=\"kn\")\n",
    "    tts.save(filename)\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def generate_caption(image):\n",
    "    start_time = time.time()\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    caption = blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"image_processing_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return caption\n",
    "\n",
    "def generate_story(caption, max_length=150):\n",
    "    start_time = time.time()\n",
    "\n",
    "    story_styles = [\n",
    "        \"A magical adventure unfolds where\",\n",
    "        \"A suspenseful tale emerges involving\",\n",
    "        \"A heartwarming story takes place as\",\n",
    "        \"An unexpected journey begins when\",\n",
    "        \"A dramatic event changes everything when\",\n",
    "        \"A mysterious secret is revealed when\",\n",
    "        \"A brave hero faces a great challenge when\",\n",
    "        \"A thrilling discovery is made as\",\n",
    "        \"A peaceful moment turns into an epic tale when\",\n",
    "        \"A legendary event occurs as\"\n",
    "    ]\n",
    "    random_prompt = random.choice(story_styles)\n",
    "    enriched_prompt = f\"The image shows {caption}. {random_prompt} unexpected events, emotions, and resolutions.\"\n",
    "\n",
    "    inputs = gpt_tokenizer.encode_plus(enriched_prompt, return_tensors=\"pt\", max_length=50, truncation=True).to(device)\n",
    "    outputs = gpt_model.generate(\n",
    "        inputs[\"input_ids\"], max_length=max_length, num_return_sequences=1,\n",
    "        no_repeat_ngram_size=3, temperature=1.2, top_k=50, top_p=0.90,\n",
    "        pad_token_id=gpt_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    story = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    efficiency_metrics[\"story_generation_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return story\n",
    "\n",
    "def generate_multiple_stories(caption, num_stories=10):\n",
    "    return [generate_story(caption) for _ in range(num_stories)]\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = Image.open(file_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        caption = generate_caption(load_image(file_path))\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        stories = generate_multiple_stories(caption)\n",
    "\n",
    "        save_all_stories(stories)\n",
    "\n",
    "\n",
    "        print(\"Generated Stories:\", stories)\n",
    "\n",
    "        story_listbox.delete(0, tk.END)\n",
    "        for i in range(10):\n",
    "            story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "        efficiency_label.config(text=\"Generated 10 unique stories.\")\n",
    "\n",
    "        def on_story_select(event):\n",
    "            selected_index = story_listbox.curselection()\n",
    "            if selected_index:\n",
    "                index = selected_index[0]\n",
    "                story = stories[index]\n",
    "\n",
    "                start_time = time.time()\n",
    "                kannada_story = translator.translate(story)\n",
    "                efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "                update_efficiency_metrics()\n",
    "\n",
    "                story_text.delete(\"1.0\", tk.END)\n",
    "                story_text.insert(tk.END, story)\n",
    "\n",
    "                kannada_text.delete(\"1.0\", tk.END)\n",
    "                kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "        story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "        \n",
    "\n",
    "def capture_image():\n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "    ret, frame = cap.read()  # Capture a frame\n",
    "    cap.release()  # Release the webcam\n",
    "    \n",
    "    if ret:\n",
    "        img_path = \"captured_image.jpg\"\n",
    "        cv2.imwrite(img_path, frame)  # Save the captured image\n",
    "\n",
    "        # Load and display the captured image\n",
    "        img = Image.open(img_path).resize((300, 300))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        # Process the image\n",
    "        caption = generate_caption(load_image(img_path))\n",
    "        caption_label.config(text=f\"Caption: {caption}\")\n",
    "        stories = generate_multiple_stories(caption)\n",
    "\n",
    "        save_all_stories(stories)\n",
    "\n",
    "        story_listbox.delete(0, tk.END)\n",
    "        for i in range(10):\n",
    "            story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "        efficiency_label.config(text=\"Generated 10 unique stories.\")\n",
    "\n",
    "        def on_story_select(event):\n",
    "            selected_index = story_listbox.curselection()\n",
    "            if selected_index:\n",
    "                index = selected_index[0]\n",
    "                story = stories[index]\n",
    "\n",
    "                start_time = time.time()\n",
    "                kannada_story = translator.translate(story)\n",
    "                efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "                update_efficiency_metrics()\n",
    "\n",
    "                story_text.delete(\"1.0\", tk.END)\n",
    "                story_text.insert(tk.END, story)\n",
    "\n",
    "                kannada_text.delete(\"1.0\", tk.END)\n",
    "                kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "        story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "\n",
    "\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        start_time = time.time()\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "def read_kannada_story():\n",
    "    kannada_story = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    if kannada_story:\n",
    "        start_time = time.time()\n",
    "        speak_kannada(kannada_story)\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "def save_story(story, kannada_story, story_index):\n",
    "    \"\"\"\n",
    "    Saves the generated stories (English & Kannada) in a single file,\n",
    "    while storing the audio files separately.\n",
    "    \"\"\"\n",
    "    # Create directories if they don't exist\n",
    "    story_dir = \"generated_stories\"\n",
    "    audio_dir = \"generated_audio\"\n",
    "    os.makedirs(story_dir, exist_ok=True)\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "    \n",
    "    # Define file path for the text file (single file for both languages)\n",
    "    story_text_path = os.path.join(story_dir, f\"story_{story_index}.txt\")\n",
    "    \n",
    "    # Define file paths for audio files\n",
    "    english_audio_path = os.path.join(audio_dir, f\"story_{story_index}_english.mp3\")\n",
    "    kannada_audio_path = os.path.join(audio_dir, f\"story_{story_index}_kannada.mp3\")\n",
    "    \n",
    "    # Save story (English & Kannada in a single file)\n",
    "    with open(story_text_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"üìñ Story {story_index} (English):\\n\")\n",
    "        file.write(story + \"\\n\\n\")\n",
    "        file.write(f\"üåç Story {story_index} (Kannada):\\n\")\n",
    "        file.write(kannada_story + \"\\n\")\n",
    "    \n",
    "    # Save audio files\n",
    "    tts_eng = gTTS(text=story, lang=\"en\")\n",
    "    tts_eng.save(english_audio_path)\n",
    "    \n",
    "    tts_kan = gTTS(text=kannada_story, lang=\"kn\")\n",
    "    tts_kan.save(kannada_audio_path)\n",
    "\n",
    "    print(f\"‚úÖ Story {story_index} saved at {story_text_path}\")\n",
    "    print(f\"üîä English Audio: {english_audio_path}\")\n",
    "    print(f\"üîä Kannada Audio: {kannada_audio_path}\")\n",
    "\n",
    "\n",
    "def save_all_stories(stories):\n",
    "    \"\"\"\n",
    "    Saves all generated stories with their Kannada translations in a single file per story.\n",
    "    \"\"\"\n",
    "    for i, story in enumerate(stories):\n",
    "        start_time = time.time()\n",
    "        kannada_story = translator.translate(story)  # Translate to Kannada\n",
    "        efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "        save_story(story, kannada_story, i + 1)\n",
    "\n",
    "\n",
    "\n",
    "# GUI Setup\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator\")\n",
    "window.geometry(\"900x800\")\n",
    "\n",
    "main_frame = tk.Frame(window)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "canvas = tk.Canvas(main_frame)\n",
    "scrollbar = Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "scrollable_frame = tk.Frame(canvas)\n",
    "scrollable_frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "image_label = Label(scrollable_frame)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "upload_button = Button(scrollable_frame, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack()\n",
    "\n",
    "capture_button = Button(scrollable_frame, text=\"Capture Image\", command=capture_image)\n",
    "capture_button.pack()\n",
    "\n",
    "caption_label = Label(scrollable_frame, text=\"Caption: \", wraplength=400, justify=\"center\")\n",
    "caption_label.pack(pady=10)\n",
    "\n",
    "story_listbox = Listbox(scrollable_frame, height=10)\n",
    "story_listbox.pack(pady=10)\n",
    "\n",
    "story_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "story_text.pack(pady=10)\n",
    "\n",
    "kannada_text = Text(scrollable_frame, wrap=\"word\", width=70, height=10)\n",
    "kannada_text.pack(pady=10)\n",
    "\n",
    "# üèÜ Efficiency Metrics Display\n",
    "efficiency_label = Label(scrollable_frame, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\", font=(\"Arial\", 12, \"bold\"))\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "read_english_button = Button(scrollable_frame, text=\"Read English Story\", command=read_english_story)\n",
    "read_english_button.pack(pady=5)\n",
    "\n",
    "read_kannada_button = Button(scrollable_frame, text=\"Read Kannada Story\", command=read_kannada_story)\n",
    "read_kannada_button.pack(pady=5)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\transformers\\generation\\utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_25284\\502150615.py\", line 267, in read_kannada_story\n",
      "    tts.save(filename)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\gtts\\tts.py\", line 334, in save\n",
      "    with open(str(savefile), \"wb\") as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'saved_audio\\\\kannada_story.mp3'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_25284\\502150615.py\", line 267, in read_kannada_story\n",
      "    tts.save(filename)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\gtts\\tts.py\", line 334, in save\n",
      "    with open(str(savefile), \"wb\") as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'saved_audio\\\\kannada_story.mp3'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_25284\\502150615.py\", line 267, in read_kannada_story\n",
      "    tts.save(filename)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\gtts\\tts.py\", line 334, in save\n",
      "    with open(str(savefile), \"wb\") as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'saved_audio\\\\kannada_story.mp3'\n",
      "c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_25284\\502150615.py\", line 267, in read_kannada_story\n",
      "    tts.save(filename)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\gtts\\tts.py\", line 334, in save\n",
      "    with open(str(savefile), \"wb\") as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'saved_audio\\\\kannada_story.mp3'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_25284\\502150615.py\", line 267, in read_kannada_story\n",
      "    tts.save(filename)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\gtts\\tts.py\", line 334, in save\n",
      "    with open(str(savefile), \"wb\") as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'saved_audio\\\\kannada_story.mp3'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_25284\\502150615.py\", line 267, in read_kannada_story\n",
      "    tts.save(filename)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\gtts\\tts.py\", line 334, in save\n",
      "    with open(str(savefile), \"wb\") as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'saved_audio\\\\kannada_story.mp3'\n",
      "c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\transformers\\generation\\utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\pydub\\utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_25284\\502150615.py\", line 498, in <lambda>\n",
      "    record_both = tk.Button(save_frame, text=\"Record Both\", command=lambda: record_audio(\"both\"))\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_25284\\502150615.py\", line 329, in record_audio\n",
      "    text_to_speech(selected_story, english_filename, lang=\"en\")\n",
      "  File \"C:\\Users\\ansl6\\AppData\\Local\\Temp\\ipykernel_25284\\502150615.py\", line 314, in text_to_speech\n",
      "    audio = AudioSegment.from_mp3(mp3_filename)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\pydub\\audio_segment.py\", line 796, in from_mp3\n",
      "    return cls.from_file(file, 'mp3', parameters=parameters)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\pydub\\audio_segment.py\", line 728, in from_file\n",
      "    info = mediainfo_json(orig_file, read_ahead_limit=read_ahead_limit)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\site-packages\\pydub\\utils.py\", line 274, in mediainfo_json\n",
      "    res = Popen(command, stdin=stdin_parameter, stdout=PIPE, stderr=PIPE)\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\subprocess.py\", line 858, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\ansl6\\anaconda3\\envs\\NAVEEN\\lib\\subprocess.py\", line 1327, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, Scrollbar, Frame, Label, Button, Text, Listbox, Spinbox , ACTIVE , ttk\n",
    "import time\n",
    "import pyttsx3\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_translator import GoogleTranslator \n",
    "import cv2\n",
    "import random\n",
    "import threading\n",
    "import os\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import sounddevice as sd\n",
    "import wave\n",
    "import pygame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "translator = GoogleTranslator(source=\"en\", target=\"kn\")\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "# Dictionary to store efficiency metrics\n",
    "efficiency_metrics = {\n",
    "    \"image_processing_time\": 0,\n",
    "    \"story_generation_time\": 0,\n",
    "    \"translation_time\": 0,\n",
    "    \"audio_generation_time\": 0\n",
    "}\n",
    "\n",
    "def update_efficiency_metrics():\n",
    "    \"\"\"\n",
    "    Updates efficiency metrics on the GUI.\n",
    "    \"\"\"\n",
    "    metrics_text = (\n",
    "        f\"üì∏ Image Processing: {efficiency_metrics['image_processing_time']:.2f} sec\\n\"\n",
    "        f\"üìñ Story Generation: {efficiency_metrics['story_generation_time']:.2f} sec\\n\"\n",
    "        f\"üåç Translation: {efficiency_metrics['translation_time']:.2f} sec\\n\"\n",
    "        f\"üîä Audio Generation: {efficiency_metrics['audio_generation_time']:.2f} sec\"\n",
    "    )\n",
    "    efficiency_label.config(text=metrics_text)\n",
    "\n",
    "SAVE_DIR = \"saved_audio\"\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "stories = []\n",
    "translator = GoogleTranslator(source=\"auto\", target=\"kn\")\n",
    "engine = pyttsx3.init()\n",
    "# Define paths for saving stories and audio\n",
    "STORY_SAVE_PATH = \"generated_stories\"\n",
    "AUDIO_SAVE_PATH = \"generated_audio\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(STORY_SAVE_PATH, exist_ok=True)\n",
    "os.makedirs(AUDIO_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "LOCAL_IMAGE_FOLDER = \"C:\\\\Users\\\\ansl6\\\\Downloads\\\\NAVEEN DS PROJECTS\\\\IR FINAL\\\\IMAGES\"\n",
    "\n",
    "def speak_kannada(text, filename=\"output.mp3\"):\n",
    "    tts = gTTS(text=text, lang=\"kn\")\n",
    "    tts.save(filename)\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def generate_caption(image):\n",
    "    start_time = time.time()\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        caption_ids = blip_model.generate(**inputs)\n",
    "    efficiency_metrics[\"image_processing_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "    return blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "\n",
    "story_prompts = [\n",
    "    \"An unexpected journey begins when...\", \"A mysterious event changes everything...\",\n",
    "    \"A hero rises in the face of danger...\", \"A magical world unfolds before them...\",\n",
    "    \"A secret from the past resurfaces...\", \"A race against time begins...\",\n",
    "    \"A lost artifact holds the key to...\", \"A twist of fate leads them to...\",\n",
    "    \"A battle between good and evil ensues...\", \"An ancient prophecy reveals the truth...\"\n",
    "]\n",
    "\n",
    "def generate_stories():\n",
    "    start_time = time.time()\n",
    "\n",
    "    global stories  \n",
    "    caption = caption_label.cget(\"text\").replace(\"Caption: \", \"\").strip()\n",
    "    \n",
    "    if not caption:\n",
    "        messagebox.showerror(\"Error\", \"No caption generated. Upload or capture an image first.\")\n",
    "        return\n",
    "\n",
    "    count = int(story_count_spinbox.get())\n",
    "    stories.clear()  # Clear previous stories before generating new ones\n",
    "\n",
    "    def generate_story_thread():\n",
    "        new_stories = []  # Temporary list to hold new stories\n",
    "        for _ in range(count):\n",
    "            prompt = f\"{random.choice(story_prompts)} {caption}\"\n",
    "            inputs = gpt_tokenizer.encode_plus(prompt, return_tensors=\"pt\", max_length=100, truncation=True).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = gpt_model.generate(\n",
    "                    inputs[\"input_ids\"], \n",
    "                    max_length=200,  \n",
    "                    temperature=0.9,  \n",
    "                    top_k=50,  \n",
    "                    top_p=0.95,  \n",
    "                    repetition_penalty=1.3\n",
    "                )\n",
    "\n",
    "            story = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "            if story not in new_stories:  \n",
    "                new_stories.append(story)  \n",
    "\n",
    "        stories.extend(new_stories)  # Update global stories list\n",
    "        window.after(0, update_story_listbox, new_stories)  # Sync with UI\n",
    "\n",
    "        efficiency_metrics[\"story_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "    threading.Thread(target=generate_story_thread, daemon=True).start()\n",
    "\n",
    "\n",
    "def update_story_listbox(stories):\n",
    "    story_listbox.delete(0, tk.END)\n",
    "    for i, story in enumerate(stories):\n",
    "        story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "    \n",
    "    def on_story_select(event):\n",
    "        selected_index = story_listbox.curselection()\n",
    "        if selected_index:\n",
    "            index = selected_index[0]\n",
    "            story_text.delete(\"1.0\", tk.END)\n",
    "            story_text.insert(tk.END, stories[index])\n",
    "            kannada_text.delete(\"1.0\", tk.END)\n",
    "            kannada_text.insert(tk.END, translator.translate(stories[index]))\n",
    "    \n",
    "    story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "\n",
    "\n",
    "\n",
    "def capture_image():\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # Use DirectShow for Windows\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Failed to access the camera.\")\n",
    "        return\n",
    "\n",
    "    time.sleep(2)  # Allow camera to adjust exposure\n",
    "\n",
    "    for _ in range(10):  # Try capturing multiple times\n",
    "        ret, frame = cap.read()\n",
    "        if ret and np.mean(frame) > 10:  # Ensure image is not black\n",
    "            break\n",
    "        time.sleep(0.1)  # Small delay before retrying\n",
    "\n",
    "    cap.release()  # Release the webcam\n",
    "\n",
    "    if not ret or np.mean(frame) <= 10:\n",
    "        messagebox.showerror(\"Error\", \"Failed to capture a clear image.\")\n",
    "        return\n",
    "\n",
    "    img_path = \"captured_image.jpg\"\n",
    "    cv2.imwrite(img_path, frame)  # Save image\n",
    "\n",
    "    # Display image in UI\n",
    "    img = Image.open(img_path).resize((300, 300))\n",
    "    img_tk = ImageTk.PhotoImage(img)\n",
    "    image_label.config(image=img_tk)\n",
    "    image_label.image = img_tk\n",
    "\n",
    "    # Process the image\n",
    "    caption = generate_caption(load_image(img_path))\n",
    "    caption_label.config(text=f\"Caption: {caption}\")\n",
    "    stories = generate_stories(caption)\n",
    "\n",
    "    save_story(stories)\n",
    "\n",
    "    story_listbox.delete(0, tk.END)\n",
    "    for i in range(10):\n",
    "        story_listbox.insert(tk.END, f\"Story {i + 1}\")\n",
    "\n",
    "\n",
    "\n",
    "    def on_story_select(event):\n",
    "        selected_index = story_listbox.curselection()\n",
    "        if selected_index:\n",
    "            index = selected_index[0]\n",
    "            story = stories[index]\n",
    "\n",
    "            start_time = time.time()\n",
    "            kannada_story = translator.translate(story)\n",
    "            efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "            update_efficiency_metrics()\n",
    "\n",
    "            story_text.delete(\"1.0\", tk.END)\n",
    "            story_text.insert(tk.END, story)\n",
    "\n",
    "            kannada_text.delete(\"1.0\", tk.END)\n",
    "            kannada_text.insert(tk.END, kannada_story)\n",
    "\n",
    "    story_listbox.bind(\"<<ListboxSelect>>\", on_story_select)\n",
    "\n",
    "# Upload image\n",
    "def upload_image(source):\n",
    "    file_types = [(\"Image Files\", \"*.png;*.jpg;*.jpeg;*.bmp;*.gif;*.tiff;*.avif\")]\n",
    "\n",
    "    if source == \"device\":\n",
    "        file_path = filedialog.askopenfilename(title=\"Select an Image from Device\", filetypes=file_types)\n",
    "    else:\n",
    "        file_path = filedialog.askopenfilename(initialdir=LOCAL_IMAGE_FOLDER, title=\"Select an Image from Project Folder\", filetypes=file_types)\n",
    "\n",
    "    if file_path:\n",
    "        process_image(file_path)\n",
    "\n",
    "def process_image(img_path):\n",
    "    img = Image.open(img_path).resize((300, 300))\n",
    "    img_tk = ImageTk.PhotoImage(img)\n",
    "    image_label.config(image=img_tk)\n",
    "    image_label.image = img_tk\n",
    "    \n",
    "    start_time = time.time()\n",
    "    caption_label.config(text=f\"Caption: {generate_caption(load_image(img_path))}\")\n",
    "    efficiency_metrics[\"translation_time\"] = time.time() - start_time\n",
    "    update_efficiency_metrics()\n",
    "\n",
    "def read_english_story():\n",
    "    story = story_text.get(\"1.0\", tk.END).strip()\n",
    "    if story:\n",
    "        start_time = time.time()\n",
    "        tts_engine.say(story)\n",
    "        tts_engine.runAndWait()\n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "\n",
    "def read_kannada_story():\n",
    "    story_in_kannada = kannada_text.get(\"1.0\", tk.END).strip()\n",
    "    \n",
    "    if story_in_kannada:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Define the filename\n",
    "        filename = os.path.join(SAVE_DIR, \"kannada_story.mp3\")\n",
    "        \n",
    "        # Convert text to speech and save\n",
    "        tts = gTTS(text=story_in_kannada, lang=\"kn\")\n",
    "        tts.save(filename)\n",
    "        \n",
    "        efficiency_metrics[\"audio_generation_time\"] = time.time() - start_time\n",
    "        update_efficiency_metrics()\n",
    "        \n",
    "        # Play the saved audio file\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(filename)\n",
    "        pygame.mixer.music.play()\n",
    "\n",
    "        while pygame.mixer.music.get_busy():  # Wait until the audio finishes playing\n",
    "            time.sleep(0.1)\n",
    "\n",
    "def save_audio(language):\n",
    "    selected_story = story_listbox.get(ACTIVE)  # Get the selected story\n",
    "    if not selected_story:\n",
    "        messagebox.showerror(\"Error\", \"No story selected.\")\n",
    "        return\n",
    "    messagebox.showinfo(\"Saving Audio\", f\"Saving audio in {language}...\")  # Replace with actual saving logic\n",
    "\n",
    "def save_story(language):\n",
    "    selected_story = story_listbox.get(ACTIVE)  # Get the selected story\n",
    "    if not selected_story:\n",
    "        messagebox.showerror(\"Error\", \"No story selected.\")\n",
    "        return\n",
    "    messagebox.showinfo(\"Saving Story\", f\"Saving story in {language}...\")  # Replace with actual saving logic\n",
    "\n",
    "\n",
    "def estimate_recording_duration(text):\n",
    "    \"\"\"Estimate duration based on story length (assuming 150 words per minute).\"\"\"\n",
    "    words_per_minute = 150\n",
    "    word_count = len(text.split())\n",
    "    return word_count / words_per_minute * 60  # Convert minutes to seconds\n",
    "\n",
    "def text_to_speech(text, filename):\n",
    "    \"\"\"Converts text to speech and saves as an audio file.\"\"\"\n",
    "    engine.save_to_file(text, filename)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def text_to_speech(text, filename, lang=\"en\"):\n",
    "    \"\"\"Convert text to speech and save as an audio file.\"\"\"\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    mp3_filename = filename.replace(\".wav\", \".mp3\")  # gTTS only supports MP3\n",
    "    tts.save(mp3_filename)\n",
    "    \n",
    "    # Convert MP3 to WAV if needed\n",
    "    if filename.endswith(\".wav\"):\n",
    "        audio = AudioSegment.from_mp3(mp3_filename)\n",
    "        audio.export(filename, format=\"wav\")\n",
    "\n",
    "def record_audio(language):\n",
    "    \"\"\"Records and saves English, Kannada, or both story audios.\"\"\"\n",
    "    selected_index = story_listbox.curselection()\n",
    "    if not selected_index:\n",
    "        messagebox.showerror(\"Error\", \"No story selected.\")\n",
    "        return\n",
    "\n",
    "    selected_index = selected_index[0]\n",
    "    selected_story = stories[selected_index]\n",
    "\n",
    "    if language in [\"english\", \"both\"]:\n",
    "        english_filename = os.path.join(AUDIO_SAVE_PATH, f\"story_english_{selected_index}.wav\")\n",
    "        text_to_speech(selected_story, english_filename, lang=\"en\")\n",
    "        messagebox.showinfo(\"Success\", f\"English audio saved:\\n{english_filename}\")\n",
    "\n",
    "    if language in [\"kannada\", \"both\"]:\n",
    "        translator = GoogleTranslator(source=\"auto\", target=\"kn\")\n",
    "        kannada_story = translator.translate(selected_story)\n",
    "        \n",
    "        if not kannada_story.strip():\n",
    "            messagebox.showerror(\"Error\", \"Kannada translation failed.\")\n",
    "            return\n",
    "        \n",
    "        kannada_filename = os.path.join(AUDIO_SAVE_PATH, f\"story_kannada_{selected_index}.wav\")\n",
    "        text_to_speech(kannada_story, kannada_filename, lang=\"kn\")\n",
    "        messagebox.showinfo(\"Success\", f\"Kannada audio saved:\\n{kannada_filename}\")\n",
    "\n",
    "def save_story(language):\n",
    "    \"\"\"Saves the selected story in English, Kannada, or both.\"\"\"\n",
    "    global stories  \n",
    "\n",
    "    selected_index = story_listbox.curselection()\n",
    "    if not selected_index:\n",
    "        messagebox.showerror(\"Error\", \"No story selected.\")\n",
    "        return\n",
    "\n",
    "    selected_index = selected_index[0]  \n",
    "\n",
    "    if selected_index >= len(stories):  \n",
    "        messagebox.showerror(\"Error\", \"Error retrieving the full story. Please regenerate the stories.\")\n",
    "        return\n",
    "\n",
    "    selected_story = stories[selected_index]  \n",
    "\n",
    "    try:\n",
    "        if language == \"english\":\n",
    "            \n",
    "            filename = os.path.join(STORY_SAVE_PATH, f\"story_english.txt\")\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(selected_story)\n",
    "            \n",
    "            messagebox.showinfo(\"Success\", f\"English story saved:\\n{filename}\")\n",
    "\n",
    "        elif language == \"kannada\":\n",
    "            \n",
    "            kannada_story = translator.translate(selected_story)  # Translate using deep_translator\n",
    "            filename = os.path.join(STORY_SAVE_PATH, f\"story_kannada.txt\")\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(kannada_story)\n",
    "            \n",
    "            messagebox.showinfo(\"Success\", f\"Kannada story saved:\\n{filename}\")\n",
    "\n",
    "        elif language == \"both\":\n",
    "            \n",
    "            kannada_story = translator.translate(selected_story)  \n",
    "\n",
    "            english_filename = os.path.join(STORY_SAVE_PATH, f\"story_english.txt\")\n",
    "            kannada_filename = os.path.join(STORY_SAVE_PATH, f\"story_kannada.txt\")\n",
    "\n",
    "            with open(english_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(selected_story)\n",
    "\n",
    "            with open(kannada_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(kannada_story)\n",
    "            \n",
    "            messagebox.showinfo(\"Success\", f\"Both English & Kannada stories saved:\\n{english_filename}\\n{kannada_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to save story: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Create Main Window\n",
    "window = tk.Tk()\n",
    "window.title(\"Image to Story Generator\")\n",
    "window.geometry(\"500x600\")\n",
    "\n",
    "# Create a Main Frame to Hold Canvas and Scrollbar\n",
    "main_frame = tk.Frame(window)\n",
    "main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# Create a Canvas for Scrolling\n",
    "canvas = tk.Canvas(main_frame)\n",
    "canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "# Add a Scrollbar Linked to the Canvas\n",
    "scrollbar = ttk.Scrollbar(main_frame, orient=tk.VERTICAL, command=canvas.yview)\n",
    "scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "# Create Scrollable Frame Inside Canvas\n",
    "content_frame = tk.Frame(canvas)\n",
    "canvas_window = canvas.create_window((0, 0), window=content_frame, anchor=\"nw\")\n",
    "\n",
    "# Function to Update Scroll Region\n",
    "def update_scroll_region(event):\n",
    "    canvas.configure(scrollregion=canvas.bbox(\"all\"))\n",
    "\n",
    "content_frame.bind(\"<Configure>\", update_scroll_region)\n",
    "\n",
    "# Enable Mouse Wheel Scrolling\n",
    "def on_canvas_scroll(event):\n",
    "    canvas.yview_scroll(-1 * (event.delta // 120), \"units\")\n",
    "\n",
    "canvas.bind_all(\"<MouseWheel>\", on_canvas_scroll)\n",
    "\n",
    "# üîπ **Widgets Inside Scrollable Frame**\n",
    "image_label = tk.Label(content_frame)\n",
    "image_label.pack()\n",
    "\n",
    "caption_label = tk.Label(content_frame, text=\"Caption: \", font=(\"Arial\", 12))\n",
    "caption_label.pack()\n",
    "\n",
    "# Upload Section\n",
    "upload_frame = tk.Frame(content_frame)\n",
    "upload_frame.pack(pady=5)\n",
    "\n",
    "upload_button = tk.Button(upload_frame, text=\"Upload Image\", command=lambda: toggle_upload_buttons())\n",
    "upload_button.pack()\n",
    "\n",
    "upload_from_device_button = tk.Button(upload_frame, text=\"From Device\", command=lambda: upload_image(\"device\"))\n",
    "upload_from_folder_button = tk.Button(upload_frame, text=\"From Folder\", command=lambda: upload_image(\"folder\"))\n",
    "\n",
    "def toggle_upload_buttons():\n",
    "    \"\"\"Toggle the visibility of upload options.\"\"\"\n",
    "    buttons = [upload_from_device_button, upload_from_folder_button]\n",
    "    if buttons[0].winfo_ismapped():\n",
    "        for btn in buttons:\n",
    "            btn.pack_forget()\n",
    "    else:\n",
    "        for btn in buttons:\n",
    "            btn.pack(pady=2)\n",
    "\n",
    "tk.Button(content_frame, text=\"Capture Image\", command=capture_image).pack()\n",
    "\n",
    "# Story Generation Section\n",
    "story_count_spinbox = tk.Spinbox(content_frame, from_=1, to=10)\n",
    "story_count_spinbox.pack(pady=5)\n",
    "\n",
    "tk.Button(content_frame, text=\"Generate Stories\", command=generate_stories).pack()\n",
    "\n",
    "story_listbox = tk.Listbox(content_frame, height=5)\n",
    "story_listbox.pack()\n",
    "\n",
    "story_text = tk.Text(content_frame, height=5, wrap=tk.WORD)\n",
    "story_text.pack()\n",
    "\n",
    "kannada_text = tk.Text(content_frame, height=5, wrap=tk.WORD)\n",
    "kannada_text.pack()\n",
    "\n",
    "            \n",
    "def update_efficiency_label():\n",
    "    if efficiency_label.winfo_exists():  # ‚úÖ Check if the widget exists before updating\n",
    "        efficiency_label.config(text=\"Updated Efficiency Metrics!\")\n",
    "# üèÜ Efficiency Metrics Display\n",
    "efficiency_label = tk.Label(content_frame, text=\"Efficiency Metrics: \", wraplength=400, justify=\"center\", font=(\"Arial\", 12, \"bold\"))\n",
    "efficiency_label.pack(pady=10)\n",
    "\n",
    "tk.Button(content_frame, text=\"Read English Story\", command=read_english_story).pack(pady=2)\n",
    "tk.Button(content_frame, text=\"Read Kannada Story\", command=read_kannada_story).pack(pady=2)\n",
    "\n",
    "# Save Buttons Frame\n",
    "save_frame = tk.Frame(content_frame)\n",
    "save_frame.pack(pady=5)\n",
    "\n",
    "# Save Audio Section\n",
    "save_audio_button = tk.Button(save_frame, text=\"Save Audio\", command=lambda: toggle_save_audio_buttons())\n",
    "save_audio_button.pack()\n",
    "\n",
    "record_english = tk.Button(save_frame, text=\"Record English\", command=lambda: record_audio(\"english\"))\n",
    "record_kannada = tk.Button(save_frame, text=\"Record Kannada\", command=lambda: record_audio(\"kannada\"))\n",
    "record_both = tk.Button(save_frame, text=\"Record Both\", command=lambda: record_audio(\"both\"))\n",
    "\n",
    "def toggle_save_audio_buttons():\n",
    "    \"\"\"Toggle the visibility of save audio options.\"\"\"\n",
    "    buttons = [record_english, record_kannada, record_both]\n",
    "    if buttons[0].winfo_ismapped():\n",
    "        for btn in buttons:\n",
    "            btn.pack_forget()\n",
    "    else:\n",
    "        for btn in buttons:\n",
    "            btn.pack(pady=2)\n",
    "\n",
    "\n",
    "# Save Story Section\n",
    "save_story_button = tk.Button(save_frame, text=\"Save Story\", command=lambda: toggle_save_story_buttons())\n",
    "save_story_button.pack()\n",
    "\n",
    "save_story_english = tk.Button(save_frame, text=\"English\", command=lambda: save_story(\"english\"))\n",
    "save_story_kannada = tk.Button(save_frame, text=\"Kannada\", command=lambda: save_story(\"kannada\"))\n",
    "save_story_both = tk.Button(save_frame, text=\"Both\", command=lambda: save_story(\"both\"))\n",
    "\n",
    "def toggle_save_story_buttons():\n",
    "    \"\"\"Toggle the visibility of save story options.\"\"\"\n",
    "    buttons = [save_story_english, save_story_kannada, save_story_both]\n",
    "    if buttons[0].winfo_ismapped():\n",
    "        for btn in buttons:\n",
    "            btn.pack_forget()\n",
    "    else:\n",
    "        for btn in buttons:\n",
    "            btn.pack(pady=2)\n",
    "\n",
    "# Run Tkinter Main Loop\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAVEEN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
